{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c75bbe6a",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e737b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "###############################\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "#Performance metrics\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "#Classifiers\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#Mutual Information - Feature Selection\n",
    "\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "#confusion matrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#Cross Validation and Best Parametrs search\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Plots\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sb\n",
    "import plotly.express as px\n",
    "\n",
    "#Data Process\n",
    "\n",
    "import zipfile\n",
    "import imageio\n",
    "from PIL import Image\n",
    "from scipy.stats import skew\n",
    "from scipy.stats import kurtosis\n",
    "\n",
    "#Data Normalization\n",
    "\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f98ea5a",
   "metadata": {},
   "source": [
    "### Data generator from MRI images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa700aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = zipfile.ZipFile('MRI.zip') \n",
    "images_names = file.namelist() \n",
    "\n",
    "print('{} MRI'.format(len(images_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0d28c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#One MRI class 0 \n",
    "image_file = file.open('brain_tumor_dataset/no/1 no.jpeg')\n",
    "image = Image.open(image_file)\n",
    "image_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cc4383",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(file_names):\n",
    "    \n",
    "    arrays_values = []\n",
    "    \n",
    "    for name in images_names:\n",
    "        \n",
    "        if 'no' in name:\n",
    "            image_file = file.open(name)\n",
    "            image = Image.open(image_file)\n",
    "            image_sequence = image.getdata()\n",
    "            image_array = np.array(image_sequence)\n",
    "            mean = np.mean(image_array)\n",
    "            variance = np.var(image_array)\n",
    "            standard_deviation = np.std(image_array)\n",
    "            skewness = skew(image_array)\n",
    "            if isinstance(skewness, np.ndarray):\n",
    "                skewness = skew(image_array)[0]\n",
    "            kurto = kurtosis(image_array)\n",
    "            if isinstance(kurto, np.ndarray):    \n",
    "                kurto = kurtosis(image_array)[0]\n",
    "            arrays_values.append([mean,variance,standard_deviation,skewness,kurto,0])\n",
    "            \n",
    "        elif 'yes' in name:\n",
    "            image_file = file.open(name)\n",
    "            image = Image.open(image_file)\n",
    "            image_sequence = image.getdata()\n",
    "            image_array = np.array(image_sequence)\n",
    "            mean = np.mean(image_array)\n",
    "            variance = np.var(image_array)\n",
    "            standard_deviation = np.std(image_array)\n",
    "            skewness = skew(image_array)\n",
    "            if isinstance(skewness, np.ndarray):\n",
    "                skewness = skew(image_array)[0]\n",
    "            kurto = kurtosis(image_array)\n",
    "            if isinstance(kurto, np.ndarray):    \n",
    "                kurto = kurtosis(image_array)[0]\n",
    "            arrays_values.append([mean,variance,standard_deviation,skewness,kurto,1])\n",
    "            \n",
    "        else:\n",
    "            return \"error\"\n",
    "        \n",
    "        \n",
    "        df_columns = ['Mean','Variance','Standard Deviation','Skewness','Kurtosis','Label']\n",
    "        data = pd.DataFrame(arrays_values,columns = df_columns)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d562e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_generator(images_names)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b48f84",
   "metadata": {},
   "source": [
    "### Plot the distribution of every feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2954d4c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,15))\n",
    "plt.suptitle('Distributions of first order features for both classes', fontsize=14, y=0.91)\n",
    "plt.subplot(3,2,1)\n",
    "\n",
    "\n",
    "sb.histplot(data = df, x = 'Mean', hue = 'Label')\n",
    "plt.legend(['Tumor','No Tumor'])\n",
    "plt.subplot(3,2,2)\n",
    "\n",
    "\n",
    "sb.histplot(data = df, x = 'Variance', hue = 'Label')\n",
    "plt.legend(['Tumor','No Tumor'])\n",
    "plt.subplot(3,2,3)\n",
    "\n",
    "\n",
    "sb.histplot(data = df, x = 'Standard Deviation', hue = 'Label')\n",
    "plt.legend(['Tumor','No Tumor'])\n",
    "plt.subplot(3,2,4)\n",
    "\n",
    "\n",
    "sb.histplot(data = df, x = 'Skewness', hue = 'Label')\n",
    "plt.legend(['Tumor','No Tumor'])\n",
    "plt.subplot(3,1,3)\n",
    "\n",
    "\n",
    "sb.histplot(data = df, x = 'Kurtosis',  log_scale=True, hue = 'Label')\n",
    "plt.legend(['Tumor','No Tumor']);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b40950",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,15))\n",
    "plt.suptitle('Distributions of second order features for both classes', fontsize=14, y=0.91)\n",
    "plt.subplot(4,2,1)\n",
    "sb.histplot(data = df, x = 'Contrast', log_scale=True, hue = 'Label')\n",
    "plt.legend(['tumor','No Tumor'])\n",
    "plt.subplot(4,2,2)\n",
    "sb.histplot(data = df, x = 'Energy', hue = 'Label')\n",
    "plt.legend(['tumor','No Tumor'])\n",
    "plt.subplot(4,2,3)\n",
    "sb.histplot(data = df, x = 'ASM', hue = 'Label')\n",
    "plt.legend(['tumor','No Tumor'])\n",
    "plt.subplot(4,2,4)\n",
    "sb.histplot(data = df, x = 'Entropy', hue = 'Label')\n",
    "plt.legend(['tumor','No Tumor'])\n",
    "plt.subplot(4,2,5)\n",
    "sb.histplot(data = df, x = 'Homogeneity', hue = 'Label')\n",
    "plt.legend(['tumor','No Tumor'])\n",
    "plt.subplot(4,2,6)\n",
    "sb.histplot(data = df, x = 'Dissimilarity', hue = 'Label')\n",
    "plt.legend(['tumor','No Tumor'])\n",
    "plt.subplot(4,1,4)\n",
    "sb.histplot(data = df, x = 'Correlation', hue = 'Label')\n",
    "plt.legend(['tumor','No Tumor']);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5f10e1",
   "metadata": {},
   "source": [
    "### Plot Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864b9474",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Plot_3D(df):\n",
    "    fig = px.scatter_3d(df, x=df.columns[0], y=df.columns[1], z=df.columns[3],color=df.columns[-1])\n",
    "    fig.show()\n",
    "    fig.write_html(\"3dPlot_{}.html\".format(df['Name'][0])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800c77b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BarPlot(df):\n",
    "    cm = sb.light_palette(\"green\", as_cmap=True)\n",
    "    s = df.style.background_gradient(cmap=cm)\n",
    "    #sb.set(style=\"whitegrid\")\n",
    "    ax = sb.barplot(y=\"Name\", x=\"Accuracy\", data=df)\n",
    "    fig=ax.get_figure()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef6607d",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a67e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection(X_train,y_train):\n",
    "    #feature selection with mutual information\n",
    "    \n",
    "    feature_mi = mutual_info_classif(X_train,y_train)\n",
    "    sorted_mifeature_index = list(feature_mi.argsort()[-13:][::-1])\n",
    "    features_mi = [X_train.columns[i] for i in sorted_mifeature_index]\n",
    "    return features_mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb39c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_model(X,y,K,randomstate = None):\n",
    "    \n",
    "    \n",
    "    featureselection = feature_selection(X,y)\n",
    "    \n",
    "    names = [\"Nearest_Neighbors\",  \n",
    "            \"Random_Forest\",'SVM']\n",
    "          \n",
    "        \n",
    "    #Classifiers we use for CV and Hyperparametrs Tuning\n",
    "    \n",
    "    classifiers = [KNeighborsClassifier(),RandomForestClassifier(),SVC()]\n",
    "    \n",
    "    #Parametrs for Classifiers \n",
    "    \n",
    "    Nearest_Neighbors_params = (\"Nearest_Neighbors\",{\"n_neighbors\": np.arange(1,15), \n",
    "                                \"weights\": [\"uniform\", \"distance\"], \"p\":[1,2]})\n",
    "\n",
    "    Random_Forest_params = (\"Random_Forest\",{\"max_depth\": range(2,100,1)})\n",
    "    \n",
    "    SVM_params = ('SVM',{\"C\": np.arange(0.001, 0.11, 0.1), \"degree\": np.arange(1,6),\n",
    "    \"kernel\": [\"linear\",\"poly\",\"rbf\",\"sigmoid\"]})\n",
    "\n",
    "    \n",
    "    Classifiers_Parameters = [Nearest_Neighbors_params,  \n",
    "                                    Random_Forest_params ,SVM_params]\n",
    "    \n",
    "    #number of best features selected from MI feature selection\n",
    "    F = [2,5,10,13]\n",
    "    \n",
    "    L = []\n",
    "    \n",
    "    for name,clf,param in zip(names, classifiers, Classifiers_Parameters):\n",
    "        if name in param[0]:\n",
    "            for i in F:\n",
    "                #take i best features from MI feature selection \n",
    "                X_train_F = X[featureselection[:i]]\n",
    "                \n",
    "                # stratified K fold CV and Hyper parametrs tuning \n",
    "                grid = GridSearchCV(estimator=clf, \n",
    "                                    param_grid = param[1], \n",
    "\n",
    "                                    scoring='accuracy',\n",
    "                                    cv = StratifiedKFold(n_splits=K,shuffle = True, random_state = randomstate).split(X_train,y_train)\n",
    "                                    ) #n_jobs = -1\n",
    "                \n",
    "                grid.fit(X_train_F, y_train)\n",
    "                \n",
    "                grid_results =  pd.concat([ pd.DataFrame(grid.cv_results_[\"params\"]),pd.DataFrame(grid.cv_results_[\"mean_test_score\"], columns=[\"Accuracy\"])],axis=1)\n",
    "                grid_results['Name'] = name \n",
    "                grid_results['n_features'] = i\n",
    "\n",
    "                print(\"For {}  classifier the best parameters are {} n_features = {} with a score of {}  \".format(name,grid.best_params_,i, grid.best_score_))\n",
    "        \n",
    "                L.append(grid_results)\n",
    "    return L"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8882022e",
   "metadata": {},
   "source": [
    "### Results "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ebd887",
   "metadata": {},
   "source": [
    "#### CV - Feature selection - Hyperparameter tuning results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae1a009",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = scaled_df.drop(['Labels'],axis = 1)\n",
    "\n",
    "y = scaled_df['Labels']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8866ecdd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = best_model(X_train,y_train,K=5,randomstate= None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5700d326",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_results = pd.concat(results[:4], ignore_index = True) \n",
    "rf_results = pd.concat(results[5:8], ignore_index = True)\n",
    "svm_results = pd.concat(results[9:],ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85eb91ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "Plot_3D(rf_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5919c0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Plot_3D(knn_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a9b57d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Plot_3D(svm_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b53260",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "maxscore_knn = pd.DataFrame(knn_results.loc[knn_results['Accuracy'].idxmax()]).T  \n",
    "maxscore_rf = pd.DataFrame(rf_results.loc[rf_results['Accuracy'].idxmax()]).T\n",
    "maxscore_svm = pd.DataFrame(svm_results.loc[svm_results['Accuracy'].idxmax()]).T\n",
    "\n",
    "max_scores= [maxscore_knn,maxscore_rf,maxscore_svm]\n",
    "\n",
    "best_results = pd.concat([maxscore_knn[['Name', 'Accuracy']], maxscore_svm[['Name', 'Accuracy']], maxscore_rf[['Name', 'Accuracy']]],ignore_index = True)\n",
    "\n",
    "BarPlot(best_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234db527",
   "metadata": {},
   "source": [
    "#### Test Data results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cedef4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_clf = KNeighborsClassifier(n_neighbors = list(maxscore_knn['n_neighbors'])[0],\n",
    "                               weights = list(maxscore_knn['weights'])[0],\n",
    "                               p = list(maxscore_knn['p'])[0])\n",
    "knn_clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred_knn = knn_clf.predict(X_test)\n",
    "\n",
    "print(\"KNN Accuracy:\",metrics.accuracy_score(y_test, y_pred_knn))        \n",
    "\n",
    "\n",
    "a = [['Nearest_Neighbors',metrics.accuracy_score(y_test, y_pred_knn)]]\n",
    "\n",
    "\n",
    "knn_test_result = pd.DataFrame(a , columns = ['Accuracy','Name'])\n",
    "\n",
    "\n",
    "confusion_matrix(y_test, y_pred_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a51453",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(max_depth = list(maxscore_rf['max_depth'])[0])\n",
    "\n",
    "rf_clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred_rf = rf_clf.predict(X_test)\n",
    "\n",
    "print(\"Random Forest Accuracy:\",metrics.accuracy_score(y_test, y_pred_rf))   \n",
    "\n",
    "b = [['Random_Forest',metrics.accuracy_score(y_test, y_pred_rf)]]\n",
    "\n",
    "rf_test_result = pd.DataFrame(b , columns = ['Accuracy','Name'])\n",
    "\n",
    "\n",
    "confusion_matrix(y_test, y_pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58110f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_clf = SVC( C = list(maxscore_svm['C'])[0],\n",
    "             degree = list(maxscore_svm['degree'])[0],\n",
    "             kernel = list(maxscore_svm['kernel'])[0])\n",
    "\n",
    "svm_clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred_svm = svm_clf.predict(X_test)\n",
    "\n",
    "print(\"SVM  Accuracy:\",metrics.accuracy_score(y_test, y_pred_svm)) \n",
    "\n",
    "\n",
    "\n",
    "c = [['SVM',metrics.accuracy_score(y_test, y_pred_svm)]]\n",
    "\n",
    "svm_test_result = pd.DataFrame(c , columns = ['Accuracy','Name'])\n",
    "\n",
    "confusion_matrix(y_test, y_pred_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0dec9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = pd.concat([knn_test_result,rf_test_result,svm_test_result],ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee50707",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a647380b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "BarPlot(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f30f49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(10,5))\n",
    "plt.barh(range(len(random_dict)), list(random_dict.values()), align='center',color=[ 'orange' ])\n",
    "plt.yticks(range(len(random_dict)), list(random_dict.keys()))\n",
    "plt.xlabel('Coefficients')\n",
    "plt.ylabel('Features')\n",
    "plt.gca().invert_yaxis()\n",
    "ax.invert_yaxis()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
